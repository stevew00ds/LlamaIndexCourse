{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.log = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '4'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '2'\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxx\"\n",
    "import openai\n",
    "openai.api_key = \"sk-xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.callbacks import CallbackManager, TokenCountingHandler\n",
    "\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer = tiktoken.encoding_for_model(\"text-embedding-ada-002\").encode,\n",
    "    verbose = True,\n",
    ")\n",
    "callback_manager = CallbackManager([token_counter])\n",
    "\n",
    "service_context = ServiceContext.from_defaults(callback_manager=callback_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Token Usage: 9760\n",
      "Embedding Token Usage: 9767\n",
      "Embedding Token Usage: 9448\n",
      "Embedding Token Usage: 9574\n",
      "Embedding Token Usage: 9608\n",
      "Embedding Token Usage: 9307\n",
      "Embedding Token Usage: 8760\n",
      "Embedding Token Usage: 9692\n",
      "Embedding Token Usage: 9648\n",
      "Embedding Token Usage: 9512\n",
      "Embedding Token Usage: 9136\n",
      "Embedding Token Usage: 9807\n",
      "Embedding Token Usage: 9540\n",
      "Embedding Token Usage: 1397\n",
      "persisting to disk\n",
      "124956\n"
     ]
    }
   ],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, StorageContext, load_index_from_storage\n",
    "\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(persist_dir='./storage/cache/andrew/sleep')\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    print('loading from disk')\n",
    "except:\n",
    "    documents = SimpleDirectoryReader('assets/AndrewHuberman/sleep').load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "    index.storage_context.persist(persist_dir='./storage/cache/andrew/sleep/')\n",
    "    print('persisting to disk')\n",
    "\n",
    "print(token_counter.total_embedding_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counter.reset_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Token Usage: 7\n",
      "LLM Prompt Token Usage: 2060\n",
      "LLM Completion Token Usage: 229\n",
      "Embedding tokens:  7 \n",
      " LLM prompts:  2060 \n",
      " LLM completitions:  229 \n",
      " Total LLM token count:  2289 \n",
      "\n",
      "Sleep enhances learning and memory by playing a crucial role in the consolidation and processing of information. During slow wave sleep, which primarily occurs in the early part of the night, motor learning and the learning of specific details about events take place. This type of sleep is important for motor skill learning and the formation of detailed memories. Slow wave sleep is characterized by the absence of acetylcholine and the presence of large amplitude brain activity. It is also associated with the release of neuromodulators such as norepinephrine and serotonin. On the other hand, rapid eye movement (REM) sleep, which occurs throughout the night with a higher percentage towards morning, is involved in memory consolidation. Dreams during REM sleep often incorporate new sensory motor experiences and memories from the day. The consolidation of memories from the hippocampus to the cortex is believed to occur during REM sleep. Additionally, the first phase of sleep, which includes slow wave sleep, is associated with the release of growth hormone and protein synthesis, both of which are important for memory formation. Consistent bedtimes and adequate sleep duration are important for optimal neurological health and memory processing.\n"
     ]
    }
   ],
   "source": [
    "response = index.as_query_engine().query(\"How does sleep enhance learning memory?\")\n",
    "print('Embedding tokens: ', token_counter.total_embedding_token_count, '\\n',\n",
    "    'LLM prompts: ', token_counter.prompt_llm_token_count, '\\n',\n",
    "    'LLM completitions: ', token_counter.completion_llm_token_count, '\\n',\n",
    "    'Total LLM token count: ', token_counter.total_llm_token_count, '\\n',\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.indices.postprocessor import SimilarityPostprocessor, KeywordNodePostprocessor\n",
    "from llama_index.response_synthesizers import get_response_synthesizer\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=4,\n",
    ")\n",
    "s_processor = SimilarityPostprocessor(similarity_cutoff=0.83)\n",
    "k_processor = KeywordNodePostprocessor(\n",
    "    exclude_keywords=[\"supplements\"]\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode = \"compact\"\n",
    ")\n",
    "\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    node_postprocessors=[k_processor],\n",
    "    response_synthesizer=response_synthesizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = query_engine.query(\"What can I do to sleep better?\")\n",
    "\n",
    "print(response.source_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
